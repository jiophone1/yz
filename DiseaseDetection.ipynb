{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 3\n",
    "\n",
    "Implementing Convolutional Neural Network(CNNs) for the task of Plant Disease detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from os import listdir\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Normalization, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Create directory for the dataset if it doesn't exist\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "# Download the dataset\n",
    "url = \"https://github.com/spMohanty/PlantVillage-Dataset/archive/refs/heads/master.zip\"\n",
    "response = requests.get(url, stream=True)\n",
    "dataset_path = \"data/plantvillage.zip\"\n",
    "\n",
    "with open(dataset_path, 'wb') as f:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "\n",
    "print(\"Dataset successfully downloaded!\")\n",
    "\n",
    "# Step 2: Unzip the dataset\n",
    "import zipfile\n",
    "\n",
    "extract_path = \"data/PlantVillage\"\n",
    "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Dataset successfully extracted!\")\n",
    "\n",
    "# Step 3: Check dataset structure\n",
    "print(\"Folders in the dataset:\", os.listdir(extract_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = \"data/PlantVillage/PlantVillage-Dataset-master/raw/color\"\n",
    "reduced_dataset_path = \"PlantVillage_Final\"  # New folder for reduced dataset\n",
    "\n",
    "# Create the reduced dataset directory\n",
    "if not os.path.exists(reduced_dataset_path):\n",
    "    os.makedirs(reduced_dataset_path)\n",
    "\n",
    "# Process each disease category\n",
    "for category in os.listdir(dataset_path):\n",
    "    class_path = os.path.join(dataset_path, category)\n",
    "    new_class_path = os.path.join(reduced_dataset_path, category)\n",
    "\n",
    "    if not os.path.exists(new_class_path):\n",
    "        os.makedirs(new_class_path)\n",
    "\n",
    "    # Get all images in the category\n",
    "    images = os.listdir(class_path)\n",
    "    total_images = len(images)\n",
    "    \n",
    "    # Keep only 25% of the images\n",
    "    keep_count = int(0.1 * total_images)\n",
    "    \n",
    "    # Randomly select images to retain\n",
    "    selected_images = random.sample(images, keep_count)\n",
    "\n",
    "    # Copy selected images to the new dataset folder\n",
    "    for img in selected_images:\n",
    "        src = os.path.join(class_path, img)\n",
    "        dest = os.path.join(new_class_path, img)\n",
    "        shutil.copy(src, dest)\n",
    "\n",
    "    print(f\"Processed {category}: Retained {keep_count}/{total_images} images.\")\n",
    "\n",
    "print(\"Dataset size reduction complete! The new dataset is saved in:\", reduced_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset path\n",
    "dataset_path = \"PlantVillage_Final/\"\n",
    "\n",
    "# Get class labels (disease categories)\n",
    "class_labels = os.listdir(dataset_path)\n",
    "print(\"Classes:\", class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "IMG_SIZE = 128  # Resize images to 128x128\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load images and resize them\n",
    "for category in class_labels:\n",
    "    class_path = os.path.join(dataset_path, category)\n",
    "    class_index = class_labels.index(category)  # Convert class name to index\n",
    "\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))  # Resize\n",
    "            data.append(img)\n",
    "            labels.append(class_index)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "data = np.array(data) / 255.0  # Normalize images\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "print(f\"Training samples: {len(xtrain)}, Validation samples: {len(xtest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical\n",
    "ytrain = to_categorical(ytrain, num_classes=len(class_labels))\n",
    "ytest = to_categorical(ytest, num_classes=len(class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain.reshape((xtrain.shape[0], IMG_SIZE, IMG_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # Removed comma\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Prevent overfitting\n",
    "model.add(Dense(len(class_labels), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=5, batch_size=32)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"plant_disease_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
